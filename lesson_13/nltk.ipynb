{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Для установки nltk потребуется выполнить:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/dmf/anaconda3/lib/python3.7/site-packages (3.3)\n",
      "Requirement already satisfied: six in /home/dmf/anaconda3/lib/python3.7/site-packages (from nltk) (1.11.0)\n",
      "\u001b[31mtwisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Загрузить данные для конкретных задач можно следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Полный пакет с данными для nltk занимает 2,2 Гб на жестком диске.\n",
    "\n",
    "Рассмотрим простейший процесс выделения лексем (или сегментирование). Можно интерпретировать по-разному, но интересны слова и предложения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Меня', 'беспокоит,', 'что', 'в', 'этом', 'будущем', 'конгломерате,', 'между', 'людьми,', 'которыми', 'мы', 'являемся,', 'и', 'теми', 'существами,', 'которыми', 'мы', 'станем', 'через', '4–5', 'поколений,', 'будет', 'мала', 'человеческая', 'доля.', 'Поэтому', 'единственный', 'для', 'нас', 'способ', '—', 'это', 'не', 'остановить', 'прогресс,', 'а', 'возглавить', 'его.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Меня беспокоит, что в этом будущем конгломерате, между людьми, которыми мы являемся, \\\n",
    "и теми существами, которыми мы станем через 4–5 поколений, будет мала человеческая доля. \\\n",
    "Поэтому единственный для нас способ — это не остановить прогресс, а возглавить его.\"\n",
    "text = text.split()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возвращает список лексем с учетом пунктуации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Меня', 'беспокоит', ',', 'что', 'в', 'этом', 'будущем', 'конгломерате', ',', 'между', 'людьми', ',', 'которыми', 'мы', 'являемся', ',', 'и', 'теми', 'существами', ',', 'которыми', 'мы', 'станем', 'через', '4–5', 'поколений', ',', 'будет', 'мала', 'человеческая', 'доля', '.', 'Поэтому', 'единственный', 'для', 'нас', 'способ', '—', 'это', 'не', 'остановить', 'прогресс', ',', 'а', 'возглавить', 'его', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "text = \"Меня беспокоит, что в этом будущем конгломерате, между людьми, которыми мы являемся, \\\n",
    "и теми существами, которыми мы станем через 4–5 поколений, будет мала человеческая доля. \\\n",
    "Поэтому единственный для нас способ — это не остановить прогресс, а возглавить его.\"\n",
    "words = word_tokenize(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждая строка - отдельное предложение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Меня беспокоит, что в этом будущем конгломерате, между людьми, которыми мы являемся, и теми существами, которыми мы станем через 4–5 поколений, будет мала человеческая доля.', 'Поэтому единственный для нас способ — это не остановить прогресс, а возглавить его.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "text = \"Меня беспокоит, что в этом будущем конгломерате, между людьми, которыми мы являемся, \\\n",
    "и теми существами, которыми мы станем через 4–5 поколений, будет мала человеческая доля. \\\n",
    "Поэтому единственный для нас способ — это не остановить прогресс, а возглавить его.\"\n",
    "sentences = sent_tokenize(text)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Меня', 'беспокоит', ',', 'что', 'в', 'этом', 'будущем', 'конгломерате', ',', 'между', 'людьми', ',', 'которыми', 'мы', 'являемся', ',', 'и', 'теми', 'существами', ',', 'которыми', 'мы', 'станем', 'через', '4–5', 'поколений', ',', 'будет', 'мала', 'человеческая', 'доля', '.']\n",
      "['Поэтому', 'единственный', 'для', 'нас', 'способ', '—', 'это', 'не', 'остановить', 'прогресс', ',', 'а', 'возглавить', 'его', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    words = word_tokenize(sentence)\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Пилотируемый полет на Марс, вероятно, состоится в 2030-х г., после того как будет создана необходимая инфраструктура для такой экспедиции.', 'Об этом заявил директор NASA Джим Брайденстайн в ходе брифинга по итогам посадки на Марсе автоматической станции Mars InSight.']\n"
     ]
    }
   ],
   "source": [
    "# Позволяет разбивать на отдельные предложения, учитывая год.\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "text = \"Пилотируемый полет на Марс, вероятно, состоится в 2030-х г., \\\n",
    "после того как будет создана необходимая инфраструктура для такой экспедиции. \\\n",
    "Об этом заявил директор NASA Джим Брайденстайн в ходе брифинга по итогам посадки \\\n",
    "на Марсе автоматической станции Mars InSight.\"\n",
    "# каждая строка - отдельное предложение\n",
    "sentences = sent_tokenize(text)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@dm_fedorov', '#nltk']\n"
     ]
    }
   ],
   "source": [
    "# можно работать с сообщениями в twitter\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "tweet = \"@dm_fedorov  #nltk\"\n",
    "print(tokenizer.tokenize(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слова используются в определенной последовательности.\n",
    "Можем получить последовательности из n-смежных слов, которые называются n-граммами. \n",
    "При n=1 получим униграммы, далее - биграммы, триграммы и т.д. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Меня', 'беспокоит,', 'что', 'в', 'этом', 'будущем', 'конгломерате,', 'между', 'людьми,', 'которыми', 'мы', 'являемся,', 'и', 'теми', 'существами,', 'которыми', 'мы', 'станем', 'через', '4–5', 'поколений,', 'будет', 'мала', 'человеческая', 'доля.', 'Поэтому', 'единственный', 'для', 'нас', 'способ', '—', 'это', 'не', 'остановить', 'прогресс,', 'а', 'возглавить', 'его.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "text = \"Меня беспокоит, что в этом будущем конгломерате, между людьми, которыми мы являемся, \\\n",
    "и теми существами, которыми мы станем через 4–5 поколений, будет мала человеческая доля. \\\n",
    "Поэтому единственный для нас способ — это не остановить прогресс, а возглавить его.\"\n",
    "text = text.split()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Меня', 'беспокоит,', 'что'),\n",
       " ('беспокоит,', 'что', 'в'),\n",
       " ('что', 'в', 'этом'),\n",
       " ('в', 'этом', 'будущем'),\n",
       " ('этом', 'будущем', 'конгломерате,'),\n",
       " ('будущем', 'конгломерате,', 'между'),\n",
       " ('конгломерате,', 'между', 'людьми,'),\n",
       " ('между', 'людьми,', 'которыми'),\n",
       " ('людьми,', 'которыми', 'мы'),\n",
       " ('которыми', 'мы', 'являемся,'),\n",
       " ('мы', 'являемся,', 'и'),\n",
       " ('являемся,', 'и', 'теми'),\n",
       " ('и', 'теми', 'существами,'),\n",
       " ('теми', 'существами,', 'которыми'),\n",
       " ('существами,', 'которыми', 'мы'),\n",
       " ('которыми', 'мы', 'станем'),\n",
       " ('мы', 'станем', 'через'),\n",
       " ('станем', 'через', '4–5'),\n",
       " ('через', '4–5', 'поколений,'),\n",
       " ('4–5', 'поколений,', 'будет'),\n",
       " ('поколений,', 'будет', 'мала'),\n",
       " ('будет', 'мала', 'человеческая'),\n",
       " ('мала', 'человеческая', 'доля.'),\n",
       " ('человеческая', 'доля.', 'Поэтому'),\n",
       " ('доля.', 'Поэтому', 'единственный'),\n",
       " ('Поэтому', 'единственный', 'для'),\n",
       " ('единственный', 'для', 'нас'),\n",
       " ('для', 'нас', 'способ'),\n",
       " ('нас', 'способ', '—'),\n",
       " ('способ', '—', 'это'),\n",
       " ('—', 'это', 'не'),\n",
       " ('это', 'не', 'остановить'),\n",
       " ('не', 'остановить', 'прогресс,'),\n",
       " ('остановить', 'прогресс,', 'а'),\n",
       " ('прогресс,', 'а', 'возглавить'),\n",
       " ('а', 'возглавить', 'его.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(text, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим грамматическую категорию - проведем частеречную разметку (POS-tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag\n",
    "tokens = word_tokenize(\"Меня беспокоит, что в этом будущем конгломерате, между людьми, которыми мы являемся, \\\n",
    "и теми существами, которыми мы станем через 4–5 поколений, будет мала человеческая доля. \\\n",
    "Поэтому единственный для нас способ — это не остановить прогресс, а возглавить его.\")\n",
    "print(pos_tag(tokens, lang='rus'))\n",
    "#nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The morphological standard of the RNC](http://www.ruscorpora.ru/en/corpora-morph.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Categorizing and Tagging Words](https://www.nltk.org/book/ch05.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализация регистра букв:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'президент'.lower() == 'Президент'.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделение основ слов (стемминг) - обычно отсечение суффикса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'рыбак'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('рыбаки')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'рыбак'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('рыбаков')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'рыбак'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('рыбаками')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
